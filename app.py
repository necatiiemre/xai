from flask import Flask, request, jsonify
import tensorflow as tf
import numpy as np
import json
import os
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.text import tokenizer_from_json
from tensorflow.keras.preprocessing.sequence import pad_sequences
from lime.lime_text import LimeTextExplainer

app = Flask(__name__)

# ğŸŒ Global yÃ¼klemeler
model, tokenizer = None, None
try:
    print("ğŸš€ Model yÃ¼kleniyor...")
    model = load_model("model.h5")
    print("âœ… model.h5 yÃ¼klendi.")
except Exception as e:
    print("âŒ model yÃ¼kleme hatasÄ±:", e)

try:
    print("ğŸš€ Tokenizer yÃ¼kleniyor...")
    with open("tokenizer.json", "r", encoding="utf-8") as f:
        tokenizer = tokenizer_from_json(f.read())
    print("âœ… tokenizer.json yÃ¼klendi.")
except Exception as e:
    print("âŒ tokenizer yÃ¼kleme hatasÄ±:", e)

maxlen = 100
explainer = LimeTextExplainer(class_names=["negatif", "pozitif"])

def predict_texts(texts):
    try:
        if model is None or tokenizer is None:
            return np.array([[0.5, 0.5]])  # default nÃ¶tr skor
        sequences = tokenizer.texts_to_sequences(texts)
        padded = pad_sequences(sequences, maxlen=maxlen)
        preds = model.predict(padded, batch_size=8)
        return np.hstack([1 - preds, preds])
    except Exception as e:
        print("âŒ Tahmin sÄ±rasÄ±nda hata:", e)
        return np.array([[0.5, 0.5]])  # fallback skor

@app.route('/predict', methods=['POST'])
def predict():
    try:
        data = request.get_json(force=True)
        text = data.get('text', '')
        if not isinstance(text, str) or len(text.strip()) == 0:
            return jsonify({'error': 'Yorum boÅŸ veya hatalÄ±.'}), 400

        print("ğŸ“ Prediction isteÄŸi:", text)
        output = predict_texts([text])
        score = float(output[0][1])
        return jsonify({'prediction': score})
    except Exception as e:
        print("âŒ /predict genel hata:", e)
        return jsonify({'error': 'Bir hata oluÅŸtu, yorum iÅŸlenemedi.'}), 500

@app.route('/lime', methods=['POST'])
def lime():
    try:
        data = request.get_json(force=True)
        text = data.get('text', '')
        if not isinstance(text, str) or len(text.strip().split()) < 3:
            return jsonify({'error': 'Yorum Ã§ok kÄ±sa, en az 3 kelime girin.'}), 400

        if model is None or tokenizer is None:
            return jsonify({'error': 'Model veya tokenizer yÃ¼klenemedi.'}), 503

        print("ğŸ§  LIME baÅŸlatÄ±ldÄ±. Yorum:", text)
        exp = explainer.explain_instance(
            text_instance=text,
            classifier_fn=predict_texts,
            labels=[1],
            num_features=10,
            num_samples=100
        )
        explanation = dict(exp.as_list(label=1))
        print("âœ… AÃ§Ä±klama Ã¼retildi:", explanation)
        return jsonify({'explanation': explanation})
    except Exception as e:
        print("âŒ /lime genel hata:", e)
        return jsonify({'error': 'AÃ§Ä±klama Ã¼retilemedi. LÃ¼tfen daha sonra tekrar deneyin.'}), 500

if __name__ == '__main__':
    port = int(os.environ.get("PORT", 5000))
    try:
        app.run(host='0.0.0.0', port=port)
    except Exception as e:
        print("âŒ Sunucu baÅŸlatma hatasÄ±:", e)
